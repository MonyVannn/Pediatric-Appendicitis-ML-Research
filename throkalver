from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

DATA_DIR = "/content/drive/MyDrive/Images/Images"
# Quick sanity check
import os
print("Exists?", os.path.isdir(DATA_DIR))
print("First items:", os.listdir(DATA_DIR)[:10])


IMG_SIZE = (224, 224)    # good for EfficientNet family
BATCH    = 16
SEED     = 13

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR, labels="inferred", label_mode="binary",
    validation_split=0.20, subset="training", seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR, labels="inferred", label_mode="binary",
    validation_split=0.20, subset="validation", seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH
)

class_names = train_ds.class_names
print("Classes detected:", class_names)

# carve a tiny test set from val (simple way)
test_take = max(1, len(val_ds)//5)
test_ds  = val_ds.take(test_take)
val_ds   = val_ds.skip(test_take)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.shuffle(2048).prefetch(AUTOTUNE)
val_ds   = val_ds.prefetch(AUTOTUNE)
test_ds  = test_ds.prefetch(AUTOTUNE)



#################################
augment = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.05),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
], name="augment")

from tensorflow.keras.applications import EfficientNetB0

base = EfficientNetB0(include_top=False, input_shape=IMG_SIZE+(3,), weights="imagenet")
base.trainable = False  # warmup (freeze backbone)

inputs = keras.Input(shape=IMG_SIZE+(3,))
x = layers.Rescaling(1./255)(inputs)
x = augment(x)
x = base(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.25)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)

model = keras.Model(inputs, outputs)
model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss="binary_crossentropy",
    metrics=["accuracy", keras.metrics.AUC(name="auc"),
             keras.metrics.Precision(name="precision"),
             keras.metrics.Recall(name="recall")]
)
model.summary()

####################################
cbs = [
    keras.callbacks.EarlyStopping(monitor="val_auc", patience=5, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2),
]

# Train with frozen backbone
history = model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=cbs)

# Fine-tune: unfreeze top ~30% (skip BatchNorms)
for layer in base.layers[int(len(base.layers)*0.7):]:
    if not isinstance(layer, layers.BatchNormalization):
        layer.trainable = True

model.compile(
    optimizer=keras.optimizers.Adam(1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy", keras.metrics.AUC(name="auc"),
             keras.metrics.Precision(name="precision"),
             keras.metrics.Recall(name="recall")]
)

history_ft = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=cbs)


####################

print("Test metrics:", model.evaluate(test_ds))
model.save("/content/appendicitis_effnetb0.h5")
