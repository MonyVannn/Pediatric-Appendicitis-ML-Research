{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bec28c4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec28c4d",
        "outputId": "d74ab100-5d9d-434b-865a-510f9afe1297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Exists? True\n",
            "First items: ['No_Appendicitis_Images', 'Appendicitis_Images']\n"
          ]
        }
      ],
      "source": [
        "# === Cell 1: Setup & Data Config ===\n",
        "import os, numpy as np, tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Path to dataset with two subfolders\n",
        "DATA_DIR = \"/content/drive/MyDrive/Images/Images\"\n",
        "\n",
        "# Training configuration\n",
        "IMG_SIZE = (320, 320)\n",
        "BATCH    = 16\n",
        "SEED     = 13\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"Exists?\", os.path.isdir(DATA_DIR))\n",
        "if os.path.isdir(DATA_DIR):\n",
        "    print(\"First items:\", os.listdir(DATA_DIR)[:10])\n",
        "else:\n",
        "    print(\"WARNING: DATA_DIR not found. Please update DATA_DIR.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f982ce7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f982ce7",
        "outputId": "d108eea6-6b78-4be0-8583-29a01e00c595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1721 files belonging to 2 classes.\n",
            "Using 1377 files for training.\n",
            "Found 1721 files belonging to 2 classes.\n",
            "Using 344 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# === Cell 2: Build Datasets (train/val) ===\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_DIR, labels=\"inferred\", label_mode=\"binary\",\n",
        "    validation_split=0.20, subset=\"training\", seed=SEED,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_DIR, labels=\"inferred\", label_mode=\"binary\",\n",
        "    validation_split=0.20, subset=\"validation\", seed=SEED,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH\n",
        ")\n",
        "\n",
        "# If have a separate test set, load it similarly, Otherwise we reuse val_ds below\n",
        "test_ds = val_ds\n",
        "\n",
        "def prep(ds, training=False):\n",
        "    # Shuffle only during training, cache+prefetch for performance\n",
        "    if training:\n",
        "        ds = ds.shuffle(1024, seed=SEED, reshuffle_each_iteration=True)\n",
        "    return ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = prep(train_ds, training=True)\n",
        "val_ds   = prep(val_ds)\n",
        "test_ds  = prep(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "290d2963",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290d2963",
        "outputId": "30e92696-b7a3-45fc-8765-b4055d1a5c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: {'neg': 1074, 'pos': 303}\n",
            "Using class weights: {0: 0.6410614525139665, 1: 2.272277227722772}\n"
          ]
        }
      ],
      "source": [
        "# === Cell 3: Compute Class Weights (handles imbalance) ===\n",
        "neg, pos = 0, 0\n",
        "for _, yb in train_ds.unbatch().take(1_000_000):  # large limit to cover full dataset\n",
        "    if int(yb.numpy()[0]) == 1:\n",
        "        pos += 1\n",
        "    else:\n",
        "        neg += 1\n",
        "total = max(1, pos+neg)\n",
        "cw = {\n",
        "    0: total/(2*max(1,neg)),\n",
        "    1: total/(2*max(1,pos)),\n",
        "}\n",
        "print(\"Class counts:\", {\"neg\":neg, \"pos\":pos})\n",
        "print(\"Using class weights:\", cw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7d2a0c1",
      "metadata": {
        "id": "c7d2a0c1"
      },
      "outputs": [],
      "source": [
        "# === Cell 4: Data Augmentations (light/medical-safe) ===\n",
        "data_augment = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),   # remove if left/right matters clinically\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"augment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "529b169b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "529b169b",
        "outputId": "b44ff72f-0644-43a4-efc9-b81c2c147a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densenet201 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1920\u001b[0m)   │    \u001b[38;5;34m18,321,984\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,921\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densenet201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,921</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,323,905\u001b[0m (69.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,323,905</span> (69.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,921\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,921</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m18,321,984\u001b[0m (69.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> (69.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# === Cell 5: Build DenseNet201 (Stage 1: Frozen base) ===\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "base = DenseNet201(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE+(3,))\n",
        "base.trainable = False\n",
        "\n",
        "inp = layers.Input(shape=IMG_SIZE+(3,))\n",
        "x   = data_augment(inp)\n",
        "x   = layers.Lambda(preprocess_input)(x)\n",
        "x   = base(x, training=False)\n",
        "x   = layers.GlobalAveragePooling2D()(x)\n",
        "x   = layers.Dropout(0.3)(x)  # adjust if over/underfitting\n",
        "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inp, out)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)  # same as before unless you want to retune\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
        "        keras.metrics.AUC(name=\"auc\"),\n",
        "        keras.metrics.AUC(name=\"auprc\", curve=\"PR\"),\n",
        "        keras.metrics.Precision(name=\"prec\"),\n",
        "        keras.metrics.Recall(name=\"rec\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "cbs = [\n",
        "    keras.callbacks.ModelCheckpoint(\"densenet201_stage1.keras\", save_best_only=True, monitor=\"val_auc\", mode=\"max\"),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=3, restore_best_weights=True),\n",
        "]\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7d42bafa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d42bafa",
        "outputId": "3ba061d5-776d-4b37-8e0f-3b53d8b01985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - acc: 0.4905 - auc: 0.5203 - auprc: 0.2598 - loss: 0.7368 - prec: 0.2338 - rec: 0.5203 - val_acc: 0.7471 - val_auc: 0.6371 - val_auprc: 0.3486 - val_loss: 0.5897 - val_prec: 0.3947 - val_rec: 0.1899\n",
            "Epoch 2/5\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 307ms/step - acc: 0.5591 - auc: 0.6266 - auprc: 0.3777 - loss: 0.6770 - prec: 0.2901 - rec: 0.6166 - val_acc: 0.7500 - val_auc: 0.6698 - val_auprc: 0.3829 - val_loss: 0.5765 - val_prec: 0.4407 - val_rec: 0.3291\n",
            "Epoch 3/5\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - acc: 0.6203 - auc: 0.6743 - auprc: 0.3881 - loss: 0.6625 - prec: 0.3419 - rec: 0.6863 - val_acc: 0.7355 - val_auc: 0.6820 - val_auprc: 0.4067 - val_loss: 0.5712 - val_prec: 0.4167 - val_rec: 0.3797\n",
            "Epoch 4/5\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - acc: 0.5854 - auc: 0.6489 - auprc: 0.3780 - loss: 0.6805 - prec: 0.3042 - rec: 0.6048 - val_acc: 0.6948 - val_auc: 0.6913 - val_auprc: 0.4023 - val_loss: 0.5974 - val_prec: 0.3750 - val_rec: 0.4937\n",
            "Epoch 5/5\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - acc: 0.6418 - auc: 0.7142 - auprc: 0.4486 - loss: 0.6352 - prec: 0.3605 - rec: 0.6978 - val_acc: 0.7006 - val_auc: 0.6966 - val_auprc: 0.4079 - val_loss: 0.5809 - val_prec: 0.3723 - val_rec: 0.4430\n"
          ]
        }
      ],
      "source": [
        "# === Cell 6: Train Stage 1 (Frozen) ===\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,                # can increase slightly if still improving\n",
        "    class_weight=cw,\n",
        "    callbacks=cbs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd426d1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd426d1c",
        "outputId": "e8e329b1-4e97-4c4d-c54b-8b264a841909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 548ms/step - accuracy: 0.7472 - auc: 0.6757 - auprc: 0.4161 - loss: 0.5324 - prec: 0.4367 - rec: 0.2952 - val_accuracy: 0.7703 - val_auc: 0.7465 - val_auprc: 0.4979 - val_loss: 0.6306 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
            "Epoch 2/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 424ms/step - accuracy: 0.8121 - auc: 0.8449 - auprc: 0.6290 - loss: 0.3937 - prec: 0.6703 - rec: 0.3853 - val_accuracy: 0.7733 - val_auc: 0.7662 - val_auprc: 0.5120 - val_loss: 0.5316 - val_prec: 0.5294 - val_rec: 0.1139\n",
            "Epoch 3/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 424ms/step - accuracy: 0.8345 - auc: 0.9015 - auprc: 0.7410 - loss: 0.3277 - prec: 0.7086 - rec: 0.4916 - val_accuracy: 0.7820 - val_auc: 0.7839 - val_auprc: 0.5369 - val_loss: 0.5670 - val_prec: 0.7000 - val_rec: 0.0886\n",
            "Epoch 4/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 427ms/step - accuracy: 0.8916 - auc: 0.9437 - auprc: 0.8560 - loss: 0.2551 - prec: 0.8131 - rec: 0.6932 - val_accuracy: 0.7791 - val_auc: 0.7969 - val_auprc: 0.5602 - val_loss: 0.5938 - val_prec: 0.6154 - val_rec: 0.1013\n",
            "Epoch 5/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 394ms/step - accuracy: 0.9434 - auc: 0.9783 - auprc: 0.9449 - loss: 0.1712 - prec: 0.9064 - rec: 0.8435 - val_accuracy: 0.7936 - val_auc: 0.7762 - val_auprc: 0.5207 - val_loss: 0.5949 - val_prec: 0.7000 - val_rec: 0.1772\n",
            "Epoch 6/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 425ms/step - accuracy: 0.9634 - auc: 0.9907 - auprc: 0.9765 - loss: 0.1158 - prec: 0.9372 - rec: 0.9032 - val_accuracy: 0.8081 - val_auc: 0.8134 - val_auprc: 0.5980 - val_loss: 0.5613 - val_prec: 0.6585 - val_rec: 0.3418\n",
            "Epoch 7/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 393ms/step - accuracy: 0.9714 - auc: 0.9948 - auprc: 0.9834 - loss: 0.0917 - prec: 0.9428 - rec: 0.9320 - val_accuracy: 0.7791 - val_auc: 0.7072 - val_auprc: 0.4336 - val_loss: 0.7959 - val_prec: 0.5556 - val_rec: 0.1899\n",
            "Epoch 8/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 393ms/step - accuracy: 0.9628 - auc: 0.9919 - auprc: 0.9767 - loss: 0.1032 - prec: 0.9158 - rec: 0.9255 - val_accuracy: 0.7791 - val_auc: 0.7740 - val_auprc: 0.4914 - val_loss: 0.7091 - val_prec: 0.5405 - val_rec: 0.2532\n",
            "Epoch 9/15\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 396ms/step - accuracy: 0.9853 - auc: 0.9989 - auprc: 0.9964 - loss: 0.0503 - prec: 0.9837 - rec: 0.9528 - val_accuracy: 0.8081 - val_auc: 0.7766 - val_auprc: 0.5787 - val_loss: 0.6029 - val_prec: 0.6585 - val_rec: 0.3418\n"
          ]
        }
      ],
      "source": [
        "# === Cell 7: Fine-tune Stage 2 (unfreeze deeper layers) ===\n",
        "base.trainable = True\n",
        "\n",
        "# Freeze a proportion (model-agnostic), e.g., first ~2/3\n",
        "cut = int(len(base.layers) * (2/3))\n",
        "for layer in base.layers[:cut]:\n",
        "    layer.trainable = False\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.AUC(name=\"auc\"),\n",
        "        tf.keras.metrics.AUC(curve=\"PR\", name=\"auprc\"),\n",
        "        tf.keras.metrics.Precision(name=\"prec\"),\n",
        "        tf.keras.metrics.Recall(name=\"rec\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "cbs_ft = [\n",
        "    keras.callbacks.ModelCheckpoint(\"densenet201_finetuned.keras\", save_best_only=True, monitor=\"val_auc\", mode=\"max\"),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=3, restore_best_weights=True),\n",
        "]\n",
        "\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=cbs_ft,\n",
        "    verbose=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "131f5e2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131f5e2b",
        "outputId": "0c059d76-c3f0-4397-babf-25bd0bf011b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold (Youden J): 0.033, Val AUC=0.817\n"
          ]
        }
      ],
      "source": [
        "# === Cell 8: Threshold Search (Youden J) on Validation ===\n",
        "import numpy as np\n",
        "y_true, y_score = [], []\n",
        "for Xb, yb in val_ds:\n",
        "    y_true.append(yb.numpy().ravel())\n",
        "    y_score.append(model.predict(Xb, verbose=0).ravel())\n",
        "y_true  = np.concatenate(y_true)\n",
        "y_score = np.concatenate(y_score)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thr = roc_curve(y_true, y_score)\n",
        "best_idx = np.argmax(tpr - fpr)  # Youden J statistic\n",
        "best_thr = float(thr[best_idx])\n",
        "\n",
        "print(f\"Best threshold (Youden J): {best_thr:.3f}, Val AUC={auc(fpr,tpr):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a50c98cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a50c98cd",
        "outputId": "deb8a6fb-3dc4-49f5-9ae9-256627fcdf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[187  78]\n",
            " [ 14  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.930     0.706     0.803       265\n",
            "         1.0      0.455     0.823     0.586        79\n",
            "\n",
            "    accuracy                          0.733       344\n",
            "   macro avg      0.692     0.764     0.694       344\n",
            "weighted avg      0.821     0.733     0.753       344\n",
            "\n",
            "Accuracy @best_thr: 0.7325581395348837\n"
          ]
        }
      ],
      "source": [
        "# === Cell 9: Optional Test-Time Augmentation (TTA) and Evaluation ===\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "def tta_predict(ds, n=5):\n",
        "    preds = []\n",
        "    for _ in range(n):\n",
        "        batch_preds = []\n",
        "        for Xb, _ in ds:\n",
        "            batch_preds.append(model.predict(Xb, verbose=0))\n",
        "        preds.append(np.concatenate(batch_preds).ravel())\n",
        "    return np.mean(np.stack(preds, axis=0), axis=0)\n",
        "\n",
        "use_tta = True\n",
        "if use_tta:\n",
        "    y_t = []\n",
        "    for _, yb in test_ds:\n",
        "        y_t.append(yb.numpy().ravel())\n",
        "    y_t = np.concatenate(y_t)\n",
        "    y_p = tta_predict(test_ds, n=5)\n",
        "else:\n",
        "    # if want to evaluate on val with no TTA, reuse the arrays from Cell 8\n",
        "    y_t, y_p = y_true, y_score\n",
        "\n",
        "y_pred = (y_p >= best_thr).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_t, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(classification_report(y_t, y_pred, digits=3))\n",
        "print(\"Accuracy @best_thr:\", accuracy_score(y_t, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}