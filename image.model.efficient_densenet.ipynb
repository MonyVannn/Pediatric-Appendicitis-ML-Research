{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Train EfficientNetB7, DenseNet121 and DenseNet201\n", "\n", "This notebook mirrors the pipeline in image.model.resnet.ipynb but trains EfficientNetB7, DenseNet121 and DenseNet201 using the same preprocessing, augmentation, splitting, class weighting, callbacks and two-phase training strategy.\n", "\n", "Notes:\n", "- Adjust the image paths if your repository layout differs.\n", "- EfficientNetB7 is large and may require reducing batch size or input resolution.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Imports\n", "import os\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from PIL import Image\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "from sklearn.utils.class_weight import compute_class_weight\n", "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n", "import tensorflow.keras.backend as K\n", "\n", "# Architecture-specific imports\n", "from tensorflow.keras.applications import DenseNet121, DenseNet201\n", "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\n", "from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input as eff_preprocess_input\n", "\n", "# Reproducibility\n", "np.random.seed(42)\n", "tf.random.set_seed(42)\n", "\n", "print('TensorFlow version:', tf.__version__)\n", "print('GPUs:', tf.config.list_physical_devices('GPU'))\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Paths - adjust if necessary\n", "appendicitis_path = 'images/appendicitis_images/'\n", "no_appendicitis_path = 'images/no_appendicitis_images/'\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def explore_dataset():\n", "    a_files = [f for f in os.listdir(appendicitis_path) if f.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png'))]\n", "    n_files = [f for f in os.listdir(no_appendicitis_path) if f.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png'))]\n", "    print(f'Appendicitis images: {len(a_files)}')\n", "    print(f'No appendicitis images: {len(n_files)}')\n", "    print(f'Total images: {len(a_files)+len(n_files)}')\n", "    return a_files, n_files\n", "\n", "a_files, n_files = explore_dataset()\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def load_and_preprocess_data(img_size=(224,224)):\n", "    images = []\n", "    labels = []\n", "\n", "    a_files = [f for f in os.listdir(appendicitis_path) if f.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png'))]\n", "    print('Loading appendicitis images...')\n", "    for fn in a_files:\n", "        try:\n", "            img = Image.open(os.path.join(appendicitis_path, fn))\n", "            if img.mode != 'RGB':\n", "                img = img.convert('RGB')\n", "            img = img.resize(img_size)\n", "            arr = np.array(img) / 255.0\n", "            images.append(arr)\n", "            labels.append(1)\n", "        except Exception as e:\n", "            print('Error loading', fn, e)\n", "\n", "    n_files = [f for f in os.listdir(no_appendicitis_path) if f.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png'))]\n", "    print('Loading no appendicitis images...')\n", "    for fn in n_files:\n", "        try:\n", "            img = Image.open(os.path.join(no_appendicitis_path, fn))\n", "            if img.mode != 'RGB':\n", "                img = img.convert('RGB')\n", "            img = img.resize(img_size)\n", "            arr = np.array(img) / 255.0\n", "            images.append(arr)\n", "            labels.append(0)\n", "        except Exception as e:\n", "            print('Error loading', fn, e)\n", "\n", "    X = np.array(images)\n", "    y = np.array(labels)\n", "    print('Loaded', len(X), 'images with shape', X.shape)\n", "    print('Label distribution:', np.bincount(y))\n", "    return X, y\n", "\n", "# Load data (may take a while depending on dataset size)\n", "# X, y = load_and_preprocess_data(img_size=(224,224))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model building utilities\n", "\n", "Functions to build backbone and full model, with preprocessing consistent with each architecture.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def build_backbone_model(arch_name, input_shape=(224,224,3), base_trainable=False):\n", "    arch = arch_name.lower()\n", "    models = {\n", "        'efficientnetb7': (EfficientNetB7, eff_preprocess_input),\n", "        'densenet121': (DenseNet121, densenet_preprocess_input),\n", "        'densenet201': (DenseNet201, densenet_preprocess_input)\n", "    }\n", "    if arch not in models:\n", "        raise ValueError('Unknown architecture: ' + arch_name)\n", "    ModelClass, preprocess_fn = models[arch]\n", "    base = ModelClass(weights='imagenet', include_top=False, input_shape=input_shape)\n", "    base.trainable = base_trainable\n", "    return base, preprocess_fn\n", "\n", "def build_full_model(arch_name, input_shape=(224,224,3)):\n", "    base_model, preprocess_fn = build_backbone_model(arch_name, input_shape=input_shape, base_trainable=False)\n", "    x_input = keras.Input(shape=input_shape, name='input_image')\n", "    if preprocess_fn is not None:\n", "        x = keras.layers.Lambda(lambda t: t * 255.0)(x_input)\n", "        x = preprocess_fn(x)\n", "    else:\n", "        x = x_input\n", "    x = base_model(x, training=False)\n", "    x = layers.GlobalAveragePooling2D()(x)\n", "    x = layers.BatchNormalization()(x)\n", "    x = layers.Dense(512, activation='relu')(x)\n", "    x = layers.Dropout(0.5)(x)\n", "    x = layers.Dense(256, activation='relu')(x)\n", "    x = layers.Dropout(0.3)(x)\n", "    out = layers.Dense(1, activation='sigmoid')(x)\n", "    model = keras.Model(inputs=x_input, outputs=out)\n", "    return model, base_model\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Metrics, compile and callbacks\n", "def f1_score(y_true, y_pred):\n", "    def recall(y_true, y_pred):\n", "        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n", "        pp = K.sum(K.round(K.clip(y_true, 0, 1)))\n", "        return tp / (pp + K.epsilon())\n", "    def precision(y_true, y_pred):\n", "        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n", "        pred_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n", "        return tp / (pred_pos + K.epsilon())\n", "    p = precision(y_true, y_pred)\n", "    r = recall(y_true, y_pred)\n", "    return 2 * ((p * r) / (p + r + K.epsilon()))\n", "\n", "def compile_model_phase(model, learning_rate=1e-3, use_f1=True):\n", "    metrics_list = ['accuracy', keras.metrics.Precision(name='precision'), keras.metrics.Recall(name='recall')]\n", "    if use_f1:\n", "        metrics_list.append(f1_score)\n", "    model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=metrics_list)\n", "\n", "def get_callbacks(arch_name, phase, monitor_metric='val_accuracy'):\n", "    fname = f'best_{arch_name}_phase{phase}.keras'\n", "    return [\n", "        EarlyStopping(monitor='val_loss', patience=8 if phase==2 else 10, restore_best_weights=True, verbose=1),\n", "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3 if phase==2 else 5, min_lr=1e-8, verbose=1),\n", "        ModelCheckpoint(fname, monitor=monitor_metric, mode='max', save_best_only=True, verbose=1)\n", "    ]\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def unfreeze_for_finetune(base_model, arch_name):\n", "    arch = arch_name.lower()\n", "    if 'efficientnet' in arch:\n", "        layers_to_unfreeze = 80\n", "    elif 'densenet121' in arch:\n", "        layers_to_unfreeze = 40\n", "    elif 'densenet201' in arch:\n", "        layers_to_unfreeze = 60\n", "    else:\n", "        layers_to_unfreeze = 20\n", "    for layer in base_model.layers[:-layers_to_unfreeze]:\n", "        layer.trainable = False\n", "    for layer in base_model.layers[-layers_to_unfreeze:]:\n", "        layer.trainable = True\n", "\n", "def evaluate_and_report(model, X_data, y_data, set_name='Validation'):\n", "    preds = model.predict(X_data, verbose=0)\n", "    binary_preds = (preds > 0.5).astype(int).ravel()\n", "    report = classification_report(y_data, binary_preds, target_names=['No Appendicitis','Appendicitis'])\n", "    print(f'\\n--- {set_name} Classification Report ---')\n", "    print(report)\n", "    cm = confusion_matrix(y_data, binary_preds)\n", "    tn, fp, fn, tp = cm.ravel()\n", "    sensitivity = tp / (tp + fn + K.epsilon())\n", "    specificity = tn / (tn + fp + K.epsilon())\n", "    print(f'Sensitivity (Recall): {sensitivity:.3f}')\n", "    print(f'Specificity: {specificity:.3f}')\n", "    return { 'confusion_matrix': cm, 'sensitivity': sensitivity, 'specificity': specificity, 'classification_report': report }\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training loop\n", "\n", "This cell runs the two-phase training (top layers then fine-tune) for each architecture.\n", "Uncomment the data-loading call above to actually load the images before running.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Uncomment the next line if X,y have not been loaded yet\n", "X, y = load_and_preprocess_data(img_size=(224,224))\n", "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n", "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n", "print(f'Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}')\n", "\n", "train_datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, zoom_range=0.1, fill_mode='nearest')\n", "val_test_datagen = ImageDataGenerator()\n", "\n", "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n", "class_weight_dict = dict(enumerate(class_weights))\n", "print('Class weights:', class_weight_dict)\n", "\n", "architectures = ['efficientnetb7', 'densenet121', 'densenet201']\n", "for arch in architectures:\n", "    print('\n' + '='*50)\n", "    print(f' TRAINING ARCHITECTURE: {arch.upper()}')\n", "    print('='*50)\n", "    model, base_model = build_full_model(arch, input_shape=(224,224,3))\n", "    compile_model_phase(model, learning_rate=1e-3, use_f1=True)\n", "    callbacks = get_callbacks(arch, phase=1, monitor_metric='val_accuracy')\n", "    model.fit(train_datagen.flow(X_train, y_train, batch_size=16), epochs=20, validation_data=(X_val, y_val), class_weight=class_weight_dict, callbacks=callbacks, verbose=1)\n", "    unfreeze_for_finetune(base_model, arch)\n", "    compile_model_phase(model, learning_rate=1e-4, use_f1=True)\n", "    callbacks = get_callbacks(arch, phase=2, monitor_metric='val_accuracy')\n", "    model.fit(train_datagen.flow(X_train, y_train, batch_size=16), epochs=15, validation_data=(X_val, y_val), class_weight=class_weight_dict, callbacks=callbacks, verbose=1)\n", "    print(f'\\n--- Final Evaluation for {arch.upper()} ---')\n", "    evaluate_and_report(model, X_val, y_val, set_name='Validation')\n", "    evaluate_and_report(model, X_test, y_test, set_name='Test')\n"]}]}